{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Parte4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BrunoBustos96/DeteccionSomnolenciaCNN/blob/main/Parte4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Desarrollo de la aplicación de la cámara web**\n",
        "\n",
        "Este notebook contiene los diferentes pasos para desarrollar la aplicación de la cámara web.\n",
        "\n",
        "El usuario necesita instalar:\n",
        "\n",
        "* homebrew (Un sistema de gestión de paquetes)\n",
        "* cmake: utilizar `brew install cmake` de la linea de comandos despues de la instalacion homebrew\n",
        "* dlib: puede ser instalado con `pip install dlib` despues de que cmake está listo\n",
        "* face_recognition: despues de haber instalado todo lo anterior, `pip install face_recognition`, una de las principales librerías de reconocimiento facial\n",
        "* OpenCV: `pip install opencv-python`, una librería muy útil para el procesamiento de imágenes\n",
        "* Playsound: Primero: `pip install -U PyObjC`, Segundo: `pip install playsound`\n",
        "\n",
        "Si se está usando **Windows**:\n",
        "\n",
        "Siga las instrucciones anteriores excepto el uso de Anaconda para instalar dlib en el paso siguiente a la instalación de cmake : `conda install -c conda-forge dlib`\n",
        "\n",
        "Más información para usuarios de Windows: [Presione aquí](https://stackoverflow.com/questions/41912372/dlib-installation-on-windows-10)"
      ],
      "metadata": {
        "id": "y7JEd5J_6afr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para la inicialización de la cámara y la vision por computador\n",
        "import cv2 \n",
        "# Libreria que define tipos de datos representadas como matrices multidimensionales\n",
        "import numpy as np \n",
        "# Playsound ejecuta sonidos de alerta, útiles para nuestra aplicación\n",
        "from playsound import playsound\n",
        "#PIL permite la edicion de imagenes desde Python\n",
        "#Image provee funciones para cargar imagenes desde archivos\n",
        "#ImageDraw provee funcionalidades de graficos en 2D en objetos de Image, creando nuevas imagenes, retoque y anotación de imagenes \n",
        "from PIL import Image, ImageDraw\n",
        "#El modulo \"face_recognition\" es necesario para la detección y reconocimiento de rostros\n",
        "import face_recognition\n",
        "# Importar la biblioteca Keras para el trabajo de DeepLearning que puede funcionar sobre TensorFlow\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "W8ABMpXT9pfn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Cargando el Mejor Modelo**"
      ],
      "metadata": {
        "id": "lDmb6Q_P9uGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asegurarse de especificar la ruta del modelo que se necesita\n",
        "eye_model = keras.models.load_model('best_model_2.h5')"
      ],
      "metadata": {
        "id": "iSrXC6hU9pdB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Función `eye_cropper`** \n",
        "\n",
        "Necesitamos esta función para optimizar la imagen para el modelo. Cuando se tome un fotograma de la cámara web, se enviará a esta función y se emitirá en un formato que el modelo sea capaz de entender, tomando en cuenta solo las características más importantes de la misma para nuestro fin."
      ],
      "metadata": {
        "id": "9XFzpm1-9yPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eye_cropper(frame):\n",
        "\n",
        "    # Crear una variable para las coordenadas de los rasgos faciales\n",
        "    facial_features_list = face_recognition.face_landmarks(frame)\n",
        "\n",
        "\n",
        "    # Se crea un array para marcar la posición de las coordenadas de los ojos \n",
        "    # y añadir las coordenadas de los ojos que no hayan sido encontrados \n",
        "\n",
        "    try:\n",
        "        eye = facial_features_list[0]['left_eye']\n",
        "    except:\n",
        "        try:\n",
        "            eye = facial_features_list[0]['right_eye']\n",
        "        except:\n",
        "            return\n",
        "\n",
        "\n",
        "    # Establecer las coordenadas X y Y maximas de los ojos\n",
        "    x_max = max([coordinate[0] for coordinate in eye])\n",
        "    x_min = min([coordinate[0] for coordinate in eye])\n",
        "    y_max = max([coordinate[1] for coordinate in eye])\n",
        "    y_min = min([coordinate[1] for coordinate in eye])\n",
        "\n",
        "\n",
        "    # Establecer el rango de las coordenadas X y Y    \n",
        "    x_range = x_max - x_min\n",
        "    y_range = y_max - y_min\n",
        "\n",
        "    # Para asegurar que el ojo entero es capturado, calcular las coordenadas de un cuadrado que tenga\n",
        "    # 50% de brecha al eje mayor y hacerlo coincidir el rango menor con el rango mayor\n",
        "    if x_range > y_range:\n",
        "        right = round(.5*x_range) + x_max\n",
        "        left = x_min - round(.5*x_range)\n",
        "        bottom = round((((right-left) - y_range))/2) + y_max\n",
        "        top = y_min - round((((right-left) - y_range))/2)\n",
        "    else:\n",
        "        bottom = round(.5*y_range) + y_max\n",
        "        top = y_min - round(.5*y_range)\n",
        "        right = round((((bottom-top) - x_range))/2) + x_max\n",
        "        left = x_min - round((((bottom-top) - x_range))/2)\n",
        "\n",
        "    # Cortar la imagen de acuerdo a las coordenadas determinadas anteriormente\n",
        "    #alls\n",
        "    cropped = frame[top:(bottom + 1), left:(right + 1)]\n",
        "\n",
        "    # Redimensionar la imagen\n",
        "    cropped = cv2.resize(cropped, (80,80))\n",
        "    image_for_prediction = cropped.reshape(-1, 80, 80, 3)\n",
        "\n",
        "    return image_for_prediction"
      ],
      "metadata": {
        "id": "UTo1DgF_9pao"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Script para la camara web**\n",
        "\n",
        "* Se accede a la webcam\n",
        "* Se implementa la función `eye_cropper` para optimizar cada imagen suelta para el modelo\n",
        "* Pasar el fotograma recortado del ojo por el modelo para predecir si está cerrado o no\n",
        "* Si la predicción da que el sujeto está cerrando los ojos durante más de 2 fotogramas, entonces lo alerta con un sonido"
      ],
      "metadata": {
        "id": "bRSjt7bx97xw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Iniciar la Webcam\n",
        "cap = cv2.VideoCapture(0)\n",
        "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
        "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
        "print(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Lanzar error en caso de que la camara web no se pueda abrir\n",
        "if not cap.isOpened():\n",
        "    raise IOError('Cannot open webcam')\n",
        "\n",
        "# Establecer un contador\n",
        "counter = 0\n",
        "\n",
        "# Crear un bucle while que se ejecuta mientras la cámara esta en uso\n",
        "while True:\n",
        "\n",
        "    # Capturar los fotogramas que son emitidos por la cámara\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # Utilizar cada dos fotogramas para gestionar la velocidad y el uso de la memoria\n",
        "    frame_count = 0\n",
        "    if frame_count == 0:\n",
        "        frame_count += 1\n",
        "        pass\n",
        "    else:\n",
        "        count = 0\n",
        "        continue\n",
        "\n",
        "    # Función llamada en el frame\n",
        "\n",
        "    image_for_prediction = eye_cropper(frame)\n",
        "    try:\n",
        "        image_for_prediction = image_for_prediction/255.0\n",
        "    except:\n",
        "        continue\n",
        "\n",
        "    # Obtener predicción del modelo\n",
        "\n",
        "    prediction = eye_model.predict(image_for_prediction)\n",
        "\n",
        "    # Basado en la predicción, mostrar si es \"Ojos Abiertos\" u \"Ojos Cerrados\"\n",
        "\n",
        "    if prediction < 0.5:\n",
        "        counter = 0\n",
        "        status = 'Open'\n",
        "\n",
        "        cv2.rectangle(frame, (round(w/2) - 110,20), (round(w/2) + 110, 80), (38,38,38), -1)\n",
        "\n",
        "        cv2.putText(frame, status, (round(w/2)-80,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,255,0), 2, cv2.LINE_4)\n",
        "        x1, y1,w1,h1 = 0,0,175,75\n",
        "        # Dibujar rectangulos de fondo negro\n",
        "        cv2.rectangle(frame, (x1,x1), (x1+w1-20, y1+h1-20), (0,0,0), -1)\n",
        "        # Adicionar texto\n",
        "        cv2.putText(frame, 'Active', (x1 +int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255,0),2)\n",
        "    else:\n",
        "        counter = counter + 1\n",
        "        status = 'Closed'\n",
        "\n",
        "        cv2.rectangle(frame, (round(w/2) - 110,20), (round(w/2) + 110, 80), (38,38,38), -1)\n",
        "\n",
        "        cv2.putText(frame, status, (round(w/2)-104,70), cv2.FONT_HERSHEY_SIMPLEX, 2, (0,0,255), 2, cv2.LINE_4)\n",
        "        x1, y1,w1,h1 = 0,0,175,75\n",
        "        # Dibujar rectangulos de fondo negro\n",
        "        cv2.rectangle(frame, (x1,x1), (x1+w1-20, y1+h1-20), (0,0,0), -1)\n",
        "        # Adicionar texto\n",
        "        cv2.putText(frame, 'Activo', (x1 +int(w1/10), y1+int(h1/2)), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255,0),2)\n",
        "\n",
        "        # Si el contador es más que 3, reproducir y mostrar alerta de que el usuario esta dormido\n",
        "        if counter > 2:\n",
        "\n",
        "            x1, y1, w1, h1 = 400,400,400,100\n",
        "            \n",
        "            cv2.rectangle(frame, (round(w/2) - 160, round(h) - 200), (round(w/2) + 160, round(h) - 120), (0,0,255), -1)\n",
        "\n",
        "            cv2.putText(frame, 'CONDUCTOR DURMIENDO', (round(w/2)-136,round(h) - 146), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,0,0), 2, cv2.LINE_4)\n",
        "\n",
        "            cv2.imshow('Drowsiness Detection', frame)\n",
        "            k = cv2.waitKey(1)\n",
        "            # Emitir sonido\n",
        "            playsound('rooster.mov')\n",
        "            counter = 1\n",
        "            continue\n",
        "    cv2.imshow('Drowsiness Detection', frame)\n",
        "    k = cv2.waitKey(1)\n",
        "    if k == 27:\n",
        "        break\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "4aVitdkl9pYL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}